{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e631a1a9-88b3-44d9-ba48-81e0cfb3037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import logging\n",
    "from speechbrain.core import AMPConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468930c6-5ecb-488b-8367-3ea98af0a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.separator import Separation\n",
    "from package.dataPrep import dataio_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278fa442-829e-4803-8b52-34432d55b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\": #  se ejecutará si ejecutas el archivo directamente, pero no si lo importas como un módulo en otro script.\n",
    "\n",
    "# Load hyperparameters file with command-line overrides\n",
    "# hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "hparams_file = './sepformer-libri2mix.yaml'\n",
    "overrides = {}\n",
    "run_opts = {'device': 'cuda:0'}\n",
    "# run_opts = {}\n",
    "# run_opts, overrides = sb.parse_arguments('fichero')\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863a07a8-bd3d-4bbc-b1ca-f6a06e5003f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/sepformer-libri2mix/4321\n"
     ]
    }
   ],
   "source": [
    "# Initialize ddp (useful only for multi-GPU DDP training)\n",
    "sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "# Create experiment directory\n",
    "sb.create_experiment_directory(\n",
    "    experiment_directory=hparams[\"output_folder\"],\n",
    "    hyperparams_to_save=hparams_file,\n",
    "    overrides=overrides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030f39a9-eaea-4ffb-9290-268dd295b431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Check if wsj0_tr is set with dynamic mixing\n",
    "# if hparams[\"dynamic_mixing\"] and not os.path.exists(hparams[\"base_folder_dm\"]):\n",
    "#     raise ValueError(\n",
    "#         \"Please, specify a valid base_folder_dm folder when using dynamic mixing\"\n",
    "#     )\n",
    "\n",
    "# Update precision to bf16 if the device is CPU and precision is fp16\n",
    "if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "    hparams[\"precision\"] = \"bf16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a0f9e8-ae02-4ac4-9dbe-80014b7799e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp16\n"
     ]
    }
   ],
   "source": [
    "print(hparams['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30dafea3-af15-4853-866f-30a6cedffa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "from package.prepare_data import prepare_librimix\n",
    "\n",
    "kwargs={\n",
    "        \"datapath\": hparams[\"data_folder\"],\n",
    "        \"savepath\": hparams[\"save_folder\"],\n",
    "        \"n_spks\": hparams[\"num_spks\"],\n",
    "        \"skip_prep\": hparams[\"skip_prep\"],\n",
    "        \"librimix_addnoise\": hparams[\"use_wham_noise\"],\n",
    "        \"fs\": hparams[\"sample_rate\"],\n",
    "    }\n",
    "\n",
    "prepare_librimix(**kwargs)\n",
    "    \n",
    "# run_on_main(\n",
    "#     prepare_librimix,\n",
    "#     kwargs={\n",
    "#         \"datapath\": hparams[\"data_folder\"],\n",
    "#         \"savepath\": hparams[\"save_folder\"],\n",
    "#         \"n_spks\": hparams[\"num_spks\"],\n",
    "#         \"skip_prep\": hparams[\"skip_prep\"],\n",
    "#         \"librimix_addnoise\": hparams[\"use_wham_noise\"],\n",
    "#         \"fs\": hparams[\"sample_rate\"],\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d323a27c-6070-4cab-879e-cf9b05f3da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset objects\n",
    "if hparams[\"dynamic_mixing\"]:\n",
    "    from dynamic_mixing import (\n",
    "        dynamic_mix_data_prep_librimix as dynamic_mix_data_prep,\n",
    "    )\n",
    "\n",
    "    # if the base_folder for dm is not processed, preprocess them\n",
    "    if \"processed\" not in hparams[\"base_folder_dm\"]:\n",
    "        # if the processed folder already exists we just use it otherwise we do the preprocessing\n",
    "        if not os.path.exists(\n",
    "            os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
    "        ):\n",
    "            from recipes.LibriMix.meta.preprocess_dynamic_mixing import (\n",
    "                resample_folder,\n",
    "            )\n",
    "\n",
    "            print(\"Resampling the base folder\")\n",
    "            run_on_main(\n",
    "                resample_folder,\n",
    "                kwargs={\n",
    "                    \"input_folder\": hparams[\"base_folder_dm\"],\n",
    "                    \"output_folder\": os.path.normpath(\n",
    "                        hparams[\"base_folder_dm\"]\n",
    "                    )\n",
    "                    + \"_processed\",\n",
    "                    \"fs\": hparams[\"sample_rate\"],\n",
    "                    \"regex\": \"**/*.flac\",\n",
    "                },\n",
    "            )\n",
    "            # adjust the base_folder_dm path\n",
    "            hparams[\"base_folder_dm\"] = (\n",
    "                os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Using the existing processed folder on the same directory as base_folder_dm\"\n",
    "            )\n",
    "            hparams[\"base_folder_dm\"] = (\n",
    "                os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
    "            )\n",
    "\n",
    "    dm_hparams = {\n",
    "        \"train_data\": hparams[\"train_data\"],\n",
    "        \"data_folder\": hparams[\"data_folder\"],\n",
    "        \"base_folder_dm\": hparams[\"base_folder_dm\"],\n",
    "        \"sample_rate\": hparams[\"sample_rate\"],\n",
    "        \"num_spks\": hparams[\"num_spks\"],\n",
    "        \"training_signal_len\": hparams[\"training_signal_len\"],\n",
    "        \"dataloader_opts\": hparams[\"dataloader_opts\"],\n",
    "    }\n",
    "\n",
    "    train_data = dynamic_mix_data_prep(dm_hparams)\n",
    "    _, valid_data, test_data = dataio_prep(hparams)\n",
    "else:\n",
    "    train_data, valid_data, test_data = dataio_prep(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b186c52-ac86-4964-bb59-2113c30d6355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.fetching - Fetch encoder.ckpt: Delegating to Huggingface hub, source speechbrain/sepformer-wsj02mix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1034c2a1f9f04ed9aaf3f7abd099d83a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading encoder.ckpt:   0%|          | 0.00/17.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.fetching - HF fetch: C:\\Users\\jaulab\\.cache\\huggingface\\hub\\models--speechbrain--sepformer-wsj02mix\\snapshots\\3a2826343a10e2d2e8a75f79aeab5ff3a2473531\\encoder.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaulab\\SSS_Enviroment\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jaulab\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] El cliente no dispone de un privilegio requerido: 'C:\\\\Users\\\\jaulab\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--sepformer-wsj02mix\\\\snapshots\\\\3a2826343a10e2d2e8a75f79aeab5ff3a2473531\\\\encoder.ckpt' -> 'results\\\\sepformer-libri2mix\\\\1234\\\\save\\\\encoder.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load pretrained model if pretrained_separator is present in the yaml\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_separator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hparams:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mrun_on_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretrained_separator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     hparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_separator\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mload_collected()\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:60\u001b[0m, in \u001b[0;36mrun_on_main\u001b[1;34m(func, args, kwargs, post_func, post_args, post_kwargs, run_post_on_main)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     post_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 60\u001b[0m \u001b[43mmain_process_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m ddp_barrier()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\utils\\distributed.py:102\u001b[0m, in \u001b[0;36mmain_process_only.<locals>.main_proc_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m MAIN_PROC_ONLY \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_main_process():\n\u001b[1;32m--> 102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:246\u001b[0m, in \u001b[0;36mPretrainer.collect_files\u001b[1;34m(self, default_source, internal_ddp_handling)\u001b[0m\n\u001b[0;32m    235\u001b[0m     path \u001b[38;5;241m=\u001b[39m fetch(\n\u001b[0;32m    236\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    237\u001b[0m         source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m         revision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    243\u001b[0m     )\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# main node is the only one calling this, so path is available\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m loadable_paths[name] \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    256\u001b[0m fetch_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:174\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, save_filename, use_auth_token, revision, huggingface_cache_dir)\u001b[0m\n\u001b[0;32m    172\u001b[0m     sourcepath \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(fetched_file)\u001b[38;5;241m.\u001b[39mabsolute()\n\u001b[0;32m    173\u001b[0m     _missing_ok_unlink(destination)\n\u001b[1;32m--> 174\u001b[0m     \u001b[43mdestination\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msourcepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m destination\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:1198\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymlink\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.symlink() not available on this system\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1198\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] El cliente no dispone de un privilegio requerido: 'C:\\\\Users\\\\jaulab\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--sepformer-wsj02mix\\\\snapshots\\\\3a2826343a10e2d2e8a75f79aeab5ff3a2473531\\\\encoder.ckpt' -> 'results\\\\sepformer-libri2mix\\\\1234\\\\save\\\\encoder.ckpt'"
     ]
    }
   ],
   "source": [
    "# Load pretrained model if pretrained_separator is present in the yaml\n",
    "if \"pretrained_separator\" in hparams:\n",
    "    run_on_main(hparams[\"pretrained_separator\"].collect_files)\n",
    "    hparams[\"pretrained_separator\"].load_collected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80df784d-2caa-4adb-8da3-ab37b427a483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9e1e49-30c8-4d62-b95b-c752ab3ad679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.core - Info: precision arg from hparam file is used\n",
      "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
      "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
      "speechbrain.core - Gradscaler enabled: True. Using precision: fp16.\n",
      "speechbrain.core - 25.7M trainable parameters in Separation\n"
     ]
    }
   ],
   "source": [
    "# Brain class initialization\n",
    "separator = Separation(\n",
    "    modules=hparams[\"modules\"],\n",
    "    opt_class=hparams[\"optimizer\"],\n",
    "    hparams=hparams,\n",
    "    run_opts=run_opts,\n",
    "    checkpointer=hparams[\"checkpointer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84446cd0-32ca-4963-8a6c-0ba9f1a1d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize the parameters if we don't use a pretrained model\n",
    "# if \"pretrained_separator\" not in hparams:\n",
    "for module in separator.modules.values():\n",
    "    separator.reset_layer_recursively(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a642e769-f9d1-4206-b4ed-91396be8d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4fcd0b0-d83d-4f52-a3b5-852b42580f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
      "speechbrain.utils.epoch_loop - Going into epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▍                                                    | 1354/50800 [2:40:38<97:46:34,  7.12s/it, train_loss=-1.17]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mseparator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_counter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataloader_opts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataloader_opts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\core.py:1555\u001b[0m, in \u001b[0;36mBrain.fit\u001b[1;34m(self, epoch_counter, train_set, valid_set, progressbar, train_loader_kwargs, valid_loader_kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;66;03m# Iterate epochs\u001b[39;00m\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_counter:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_valid(valid_set\u001b[38;5;241m=\u001b[39mvalid_set, epoch\u001b[38;5;241m=\u001b[39mepoch, enable\u001b[38;5;241m=\u001b[39menable)\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;66;03m# Debug mode only runs a few epochs\u001b[39;00m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\core.py:1384\u001b[0m, in \u001b[0;36mBrain._fit_train\u001b[1;34m(self, train_set, epoch, enable)\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1383\u001b[0m steps_since_ckpt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1384\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_average(\n\u001b[0;32m   1386\u001b[0m     loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_train_loss\n\u001b[0;32m   1387\u001b[0m )\n\u001b[0;32m   1388\u001b[0m t\u001b[38;5;241m.\u001b[39mset_postfix(train_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_train_loss)\n",
      "File \u001b[1;32m~\\Desktop\\ReSepFormer_LibriMix\\package\\separator.py:111\u001b[0m, in \u001b[0;36mSeparation.fit_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(\n\u001b[0;32m    106\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mamp\u001b[38;5;241m.\u001b[39mdtype, device_type\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mtype,\n\u001b[0;32m    107\u001b[0m ):\n\u001b[0;32m    108\u001b[0m     predictions, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_forward(\n\u001b[0;32m    109\u001b[0m         mixture, targets, sb\u001b[38;5;241m.\u001b[39mStage\u001b[38;5;241m.\u001b[39mTRAIN, noise\n\u001b[0;32m    110\u001b[0m     )\n\u001b[1;32m--> 111\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_objectives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# hard threshold the easy dataitems\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mthreshold_byloss:\n",
      "File \u001b[1;32m~\\Desktop\\ReSepFormer_LibriMix\\package\\separator.py:85\u001b[0m, in \u001b[0;36mSeparation.compute_objectives\u001b[1;34m(self, predictions, targets)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_objectives\u001b[39m(\u001b[38;5;28mself\u001b[39m, predictions, targets):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the si-snr loss\"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\nnet\\losses.py:962\u001b[0m, in \u001b[0;36mget_si_snr_with_pitwrapper\u001b[1;34m(source, estimate_source)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This function wraps si_snr calculation with the speechbrain pit-wrapper.\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \n\u001b[0;32m    942\u001b[0m \u001b[38;5;124;03mArguments:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;124;03mtensor([135.2284, 135.2284, 135.2284])\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    961\u001b[0m pit_si_snr \u001b[38;5;241m=\u001b[39m PitWrapper(cal_si_snr)\n\u001b[1;32m--> 962\u001b[0m loss, perms \u001b[38;5;241m=\u001b[39m \u001b[43mpit_si_snr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\nnet\\losses.py:240\u001b[0m, in \u001b[0;36mPitWrapper.forward\u001b[1;34m(self, preds, targets)\u001b[0m\n\u001b[0;32m    238\u001b[0m perms \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds, targets):\n\u001b[1;32m--> 240\u001b[0m     loss, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opt_perm_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     perms\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m    242\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\nnet\\losses.py:184\u001b[0m, in \u001b[0;36mPitWrapper._opt_perm_loss\u001b[1;34m(self, pred, target)\u001b[0m\n\u001b[0;32m    177\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pred\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)], n_sources, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    179\u001b[0m )\n\u001b[0;32m    180\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)], n_sources\n\u001b[0;32m    182\u001b[0m )\n\u001b[1;32m--> 184\u001b[0m loss_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28mlen\u001b[39m(loss_mat\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    187\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase loss should not perform any reduction operation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m mean_over \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loss_mat\u001b[38;5;241m.\u001b[39mshape))]\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\Lib\\site-packages\\speechbrain\\nnet\\losses.py:1012\u001b[0m, in \u001b[0;36mcal_si_snr\u001b[1;34m(source, estimate_source)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m source\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m estimate_source\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m   1010\u001b[0m device \u001b[38;5;241m=\u001b[39m estimate_source\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m-> 1012\u001b[0m source_lengths \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mestimate_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mestimate_source\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m mask \u001b[38;5;241m=\u001b[39m get_mask(source, source_lengths)\n\u001b[0;32m   1016\u001b[0m estimate_source \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "separator.fit(\n",
    "    separator.hparams.epoch_counter,\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34964f93-0b1e-41f9-b15f-276561736fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "separator.evaluate(test_data, min_key=\"si-snr\")\n",
    "separator.save_results(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
