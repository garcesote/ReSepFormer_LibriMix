{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e631a1a9-88b3-44d9-ba48-81e0cfb3037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import speechbrain as sb\n",
    "import speechbrain.nnet.schedulers as schedulers\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import logging\n",
    "from speechbrain.core import AMPConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468930c6-5ecb-488b-8367-3ea98af0a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.separator import Separation\n",
    "import package.dataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "278fa442-829e-4803-8b52-34432d55b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\": #  se ejecutará si ejecutas el archivo directamente, pero no si lo importas como un módulo en otro script.\n",
    "\n",
    "# Load hyperparameters file with command-line overrides\n",
    "# hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "hparams_file = './sepformer-libri2mix.yaml'\n",
    "overrides = {}\n",
    "# run_opts, overrides = sb.parse_arguments('fichero')\n",
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin, overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "863a07a8-bd3d-4bbc-b1ca-f6a06e5003f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.core - Beginning experiment!\n",
      "speechbrain.core - Experiment folder: results/sepformer-libri2mix/1234\n"
     ]
    }
   ],
   "source": [
    "# Initialize ddp (useful only for multi-GPU DDP training)\n",
    "# sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "# Create experiment directory\n",
    "sb.create_experiment_directory(\n",
    "    experiment_directory=hparams[\"output_folder\"],\n",
    "    hyperparams_to_save=hparams_file,\n",
    "    overrides=overrides,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "030f39a9-eaea-4ffb-9290-268dd295b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if wsj0_tr is set with dynamic mixing\n",
    "# if hparams[\"dynamic_mixing\"] and not os.path.exists(hparams[\"base_folder_dm\"]):\n",
    "#     raise ValueError(\n",
    "#         \"Please, specify a valid base_folder_dm folder when using dynamic mixing\"\n",
    "#     )\n",
    "\n",
    "# Update precision to bf16 if the device is CPU and precision is fp16\n",
    "if run_opts.get(\"device\") == \"cpu\" and hparams.get(\"precision\") == \"fp16\":\n",
    "    hparams[\"precision\"] = \"bf16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30dafea3-af15-4853-866f-30a6cedffa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "from package.prepare_data import prepare_librimix\n",
    "\n",
    "kwargs={\n",
    "        \"datapath\": hparams[\"data_folder\"],\n",
    "        \"savepath\": hparams[\"save_folder\"],\n",
    "        \"n_spks\": hparams[\"num_spks\"],\n",
    "        \"skip_prep\": hparams[\"skip_prep\"],\n",
    "        \"librimix_addnoise\": hparams[\"use_wham_noise\"],\n",
    "        \"fs\": hparams[\"sample_rate\"],\n",
    "    }\n",
    "\n",
    "prepare_librimix(**kwargs)\n",
    "    \n",
    "# run_on_main(\n",
    "#     prepare_librimix,\n",
    "#     kwargs={\n",
    "#         \"datapath\": hparams[\"data_folder\"],\n",
    "#         \"savepath\": hparams[\"save_folder\"],\n",
    "#         \"n_spks\": hparams[\"num_spks\"],\n",
    "#         \"skip_prep\": hparams[\"skip_prep\"],\n",
    "#         \"librimix_addnoise\": hparams[\"use_wham_noise\"],\n",
    "#         \"fs\": hparams[\"sample_rate\"],\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d323a27c-6070-4cab-879e-cf9b05f3da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset objects\n",
    "if hparams[\"dynamic_mixing\"]:\n",
    "    from dynamic_mixing import (\n",
    "        dynamic_mix_data_prep_librimix as dynamic_mix_data_prep,\n",
    "    )\n",
    "\n",
    "    # if the base_folder for dm is not processed, preprocess them\n",
    "    if \"processed\" not in hparams[\"base_folder_dm\"]:\n",
    "        # if the processed folder already exists we just use it otherwise we do the preprocessing\n",
    "        if not os.path.exists(\n",
    "            os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
    "        ):\n",
    "            from recipes.LibriMix.meta.preprocess_dynamic_mixing import (\n",
    "                resample_folder,\n",
    "            )\n",
    "\n",
    "            print(\"Resampling the base folder\")\n",
    "            run_on_main(\n",
    "                resample_folder,\n",
    "                kwargs={\n",
    "                    \"input_folder\": hparams[\"base_folder_dm\"],\n",
    "                    \"output_folder\": os.path.normpath(\n",
    "                        hparams[\"base_folder_dm\"]\n",
    "                    )\n",
    "                    + \"_processed\",\n",
    "                    \"fs\": hparams[\"sample_rate\"],\n",
    "                    \"regex\": \"**/*.flac\",\n",
    "                },\n",
    "            )\n",
    "            # adjust the base_folder_dm path\n",
    "            hparams[\"base_folder_dm\"] = (\n",
    "                os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"Using the existing processed folder on the same directory as base_folder_dm\"\n",
    "            )\n",
    "            hparams[\"base_folder_dm\"] = (\n",
    "                os.path.normpath(hparams[\"base_folder_dm\"]) + \"_processed\"\n",
    "            )\n",
    "\n",
    "    dm_hparams = {\n",
    "        \"train_data\": hparams[\"train_data\"],\n",
    "        \"data_folder\": hparams[\"data_folder\"],\n",
    "        \"base_folder_dm\": hparams[\"base_folder_dm\"],\n",
    "        \"sample_rate\": hparams[\"sample_rate\"],\n",
    "        \"num_spks\": hparams[\"num_spks\"],\n",
    "        \"training_signal_len\": hparams[\"training_signal_len\"],\n",
    "        \"dataloader_opts\": hparams[\"dataloader_opts\"],\n",
    "    }\n",
    "\n",
    "    train_data = dynamic_mix_data_prep(dm_hparams)\n",
    "    _, valid_data, test_data = dataio_prep(hparams)\n",
    "else:\n",
    "    train_data, valid_data, test_data = dataio_prep(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b186c52-ac86-4964-bb59-2113c30d6355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.fetching - Fetch encoder.ckpt: Delegating to Huggingface hub, source speechbrain/sepformer-wsj02mix.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6750aadaf44cf29e1916ee601f4782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading encoder.ckpt:   0%|          | 0.00/17.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.utils.fetching - HF fetch: C:\\Users\\garce\\.cache\\huggingface\\hub\\models--speechbrain--sepformer-wsj02mix\\snapshots\\3a2826343a10e2d2e8a75f79aeab5ff3a2473531\\encoder.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garce\\SSS_Enviroment\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\garce\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] El cliente no dispone de un privilegio requerido: 'C:\\\\Users\\\\garce\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--sepformer-wsj02mix\\\\snapshots\\\\3a2826343a10e2d2e8a75f79aeab5ff3a2473531\\\\encoder.ckpt' -> 'results\\\\sepformer-libri2mix\\\\1234\\\\save\\\\encoder.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load pretrained model if pretrained_separator is present in the yaml\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_separator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m hparams:\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mrun_on_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretrained_separator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     hparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretrained_separator\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mload_collected()\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\lib\\site-packages\\speechbrain\\utils\\distributed.py:60\u001b[0m, in \u001b[0;36mrun_on_main\u001b[1;34m(func, args, kwargs, post_func, post_args, post_kwargs, run_post_on_main)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     post_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 60\u001b[0m main_process_only(func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     61\u001b[0m ddp_barrier()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m post_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\lib\\site-packages\\speechbrain\\utils\\distributed.py:102\u001b[0m, in \u001b[0;36mmain_process_only.<locals>.main_proc_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m MAIN_PROC_ONLY \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m if_main_process():\n\u001b[1;32m--> 102\u001b[0m     result \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:246\u001b[0m, in \u001b[0;36mPretrainer.collect_files\u001b[1;34m(self, default_source, internal_ddp_handling)\u001b[0m\n\u001b[0;32m    235\u001b[0m     path \u001b[38;5;241m=\u001b[39m fetch(\n\u001b[0;32m    236\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    237\u001b[0m         source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m         revision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    243\u001b[0m     )\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# main node is the only one calling this, so path is available\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43msavedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m loadable_paths[name] \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    256\u001b[0m fetch_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\lib\\site-packages\\speechbrain\\utils\\fetching.py:174\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(filename, source, savedir, overwrite, save_filename, use_auth_token, revision, huggingface_cache_dir)\u001b[0m\n\u001b[0;32m    172\u001b[0m     sourcepath \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(fetched_file)\u001b[38;5;241m.\u001b[39mabsolute()\n\u001b[0;32m    173\u001b[0m     _missing_ok_unlink(destination)\n\u001b[1;32m--> 174\u001b[0m     \u001b[43mdestination\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msourcepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m destination\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pathlib.py:1255\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msymlink_to\u001b[39m(\u001b[38;5;28mself\u001b[39m, target, target_is_directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;124;03m    Make this path a symlink pointing to the target path.\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;124;03m    Note the order of arguments (link, target) is the reverse of os.symlink.\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1255\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] El cliente no dispone de un privilegio requerido: 'C:\\\\Users\\\\garce\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--sepformer-wsj02mix\\\\snapshots\\\\3a2826343a10e2d2e8a75f79aeab5ff3a2473531\\\\encoder.ckpt' -> 'results\\\\sepformer-libri2mix\\\\1234\\\\save\\\\encoder.ckpt'"
     ]
    }
   ],
   "source": [
    "# Load pretrained model if pretrained_separator is present in the yaml\n",
    "if \"pretrained_separator\" in hparams:\n",
    "    run_on_main(hparams[\"pretrained_separator\"].collect_files)\n",
    "    hparams[\"pretrained_separator\"].load_collected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80df784d-2caa-4adb-8da3-ab37b427a483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a9e1e49-30c8-4d62-b95b-c752ab3ad679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speechbrain.core - Info: precision arg from hparam file is used\n",
      "speechbrain.core - Info: noprogressbar arg from hparam file is used\n",
      "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Brain class initialization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m separator \u001b[38;5;241m=\u001b[39m \u001b[43mSeparation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodules\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopt_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpointer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\lib\\site-packages\\speechbrain\\core.py:715\u001b[0m, in \u001b[0;36mBrain.__init__\u001b[1;34m(self, modules, opt_class, hparams, run_opts, checkpointer)\u001b[0m\n\u001b[0;32m    713\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[1;32m--> 715\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# Put modules on the right device, accessible with dot notation\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleDict(modules)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\SSS_Enviroment\\lib\\site-packages\\torch\\cuda\\__init__.py:404\u001b[0m, in \u001b[0;36mset_device\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    402\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 404\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_setDevice\u001b[49m(device)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "source": [
    "# Brain class initialization\n",
    "separator = Separation(\n",
    "    modules=hparams[\"modules\"],\n",
    "    opt_class=hparams[\"optimizer\"],\n",
    "    hparams=hparams,\n",
    "    run_opts=run_opts,\n",
    "    checkpointer=hparams[\"checkpointer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84446cd0-32ca-4963-8a6c-0ba9f1a1d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize the parameters if we don't use a pretrained model\n",
    "if \"pretrained_separator\" not in hparams:\n",
    "    for module in separator.modules.values():\n",
    "        separator.reset_layer_recursively(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fcd0b0-d83d-4f52-a3b5-852b42580f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "separator.fit(\n",
    "    separator.hparams.epoch_counter,\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    "    valid_loader_kwargs=hparams[\"dataloader_opts\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34964f93-0b1e-41f9-b15f-276561736fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "separator.evaluate(test_data, min_key=\"si-snr\")\n",
    "separator.save_results(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
